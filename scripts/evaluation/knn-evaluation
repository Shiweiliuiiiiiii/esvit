#!/bin/bash
#SBATCH --job-name=esvit_slak_15x15_bn_resume
#SBATCH -p gpu
#SBATCH -N 1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=4
#SBATCH --gpus=4
#SBATCH -t 3-11:59:59
#SBATCH --exclusive
#SBATCH --cpus-per-task=72
#SBATCH -o esvit_slak_15x15_bn_resume.out

source /home/sliu/miniconda3/etc/profile.d/conda.sh
source activate LoRA


PROJ_PATH=your_esvit_project_path
DATA_PATH=$PROJ_PATH/project/data/imagenet

OUT_PATH=$PROJ_PATH/exp_output/esvit_exp/swin/swin_tiny/bl_lr0.0005_gpu16_bs32_dense_multicrop_epoch300
CKPT_PATH=$PROJ_PATH/exp_output/esvit_exp/swin/swin_tiny/bl_lr0.0005_gpu16_bs32_dense_multicrop_epoch300/checkpoint.pth

# knn
python -m torch.distributed.launch --nproc_per_node=4 eval_knn.py --data_path /projects/2/managed_datasets/imagenet/train/ \
--dump_features $OUT_PATH/features/epoch0300 --pretrained_weights ~/project_space/esvit/output/esvit_exp/ssl/slak_tiny_imagenet_7x7/checkpoint.pth \
--checkpoint_key teacher \
--batch_size_per_gpu 256 --arch SLaK_tiny --cfg experiments/imagenet/swin/swin_tiny_patch4_window7_224.yaml \
MODEL.NUM_CLASSES 0

# linear
#python -m torch.distributed.launch --nproc_per_node=4 eval_linear.py \
#--data_path  /projects/2/managed_datasets/imagenet/train/ \
#--output_dir ~/project_space/esvit/output/esvit_exp/ssl/slak_tiny_imagenet_7x7/ \
#--pretrained_weights ~/project_space/esvit/output/esvit_exp/ssl/slak_tiny_imagenet_7x7/checkpoint.pth --checkpoint_key teacher \
#--batch_size_per_gpu 256 --arch SLaK_tiny --kernel_size 7 7 7 7 100 --bn True  \
#--cfg experiments/imagenet/swin/swin_tiny_patch4_window7_224.yaml \
#--n_last_blocks 4 --num_labels 1000 MODEL.NUM_CLASSES 0




